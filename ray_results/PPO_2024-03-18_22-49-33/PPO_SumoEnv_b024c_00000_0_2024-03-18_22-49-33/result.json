{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"raththanpitiya_jnct_n4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.023644247452633257, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -5.119761311410305e-05, "policy_loss": -0.0003814975323621184, "vf_loss": 0.0003303002340042364, "vf_explained_var": -0.10460871799538533, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.980593571268643, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2433621220290663, "policy_loss": -0.000360019798730112, "vf_loss": 3.243722134331862, "vf_explained_var": 0.12062843013554811, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_s_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6496230750965575, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7487979705135026, "policy_loss": -0.00045192626081795123, "vf_loss": 2.749249906713764, "vf_explained_var": 0.06287810628612836, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_e2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6843060933150507, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.939245580136776, "policy_loss": 0.00036931212331789236, "vf_loss": 8.938876269261042, "vf_explained_var": -0.0007069561630487442, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9153547793005904, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.775156049927075, "policy_loss": -0.014865012898129255, "vf_loss": 9.787675934036573, "vf_explained_var": -0.0033362644414107003, "kl": 0.011725730197807122, "entropy": 1.374307052915295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_w1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4416957477806136, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7536117013543844, "policy_loss": -0.00016563395474804564, "vf_loss": 1.7537773356462518, "vf_explained_var": 0.1351190178344647, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_s1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8569599857010568, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30262726166596016, "policy_loss": -0.0001464170959176651, "vf_loss": 0.3027736792185654, "vf_explained_var": 0.27387024499475954, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.567552959670623, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.556414315104485, "policy_loss": -0.013172049613058335, "vf_loss": 4.5667356215417385, "vf_explained_var": 0.12119346242398024, "kl": 0.014253595385661419, "entropy": 1.3719736815740664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5196960896321495, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.799577208360036, "policy_loss": 0.00038958159857429566, "vf_loss": 9.799187612533569, "vf_explained_var": -0.0003426916276415189, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6965735358186066, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.472418156266212, "policy_loss": -0.0007430354351527057, "vf_loss": 9.47316118478775, "vf_explained_var": 0.004285719742377599, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_e_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.065723621189439, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6127446430424849, "policy_loss": -0.0006845052984620754, "vf_loss": 0.6134291487590721, "vf_explained_var": 0.3785775167867541, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.025944087250779, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6398499286733568, "policy_loss": -0.007324951448147961, "vf_loss": 0.6454851811751723, "vf_explained_var": 0.21248482670634986, "kl": 0.008448493883777466, "entropy": 0.6849498241518934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8983040453245243, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5805805842081706, "policy_loss": -0.009220452387429154, "vf_loss": 1.5878319581970572, "vf_explained_var": 0.17929671239107847, "kl": 0.009845417950377527, "entropy": 1.376377068211635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct_s": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.18054191951135484, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.04472696465648672, "policy_loss": 0.00023244082597860446, "vf_loss": 0.044494523770724, "vf_explained_var": 0.041710275784134866, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0073881015880033, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.34573321311424177, "policy_loss": 0.00023885218300468599, "vf_loss": 0.3454943605931476, "vf_explained_var": 0.4499399387588104, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 60000, "num_agent_steps_trained": 60000}, "sampler_results": {"episode_reward_max": -526.9900000000001, "episode_reward_min": -731.5500000000008, "episode_reward_mean": -640.8340000000001, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -72.34, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -14.509999999999996, "delkanda_w_jnct": -129.85, "gamsaba_jnct": -236.87, "gamsaba_s_jnct": -12.59, "gamsaba_w1_jnct": -5.480000000000001, "pepiliyana_e_jnct": -1.07, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -2.3900000000000006, "pepiliyana_s1_jnct": -2.28, "pepiliyana_w_jnct": -387.82, "raththanpitiya_jnct": -3.21, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 0.0}, "policy_reward_max": {"delkanda_e2_jnct": -38.52, "delkanda_jnct": -0.29, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -56.81, "gamsaba_jnct": -106.31, "gamsaba_s_jnct": -5.551115123125783e-17, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 0.09000000000000008, "pepiliyana_jnct": -5.77, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 4.996003610813204e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.36000000000000015, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 2.7755575615628914e-17}, "policy_reward_mean": {"delkanda_e2_jnct": -54.14899999999999, "delkanda_jnct": -2.6719999999999997, "delkanda_n2_jnct": -5.520999999999999, "delkanda_w_jnct": -84.54400000000001, "gamsaba_jnct": -183.171, "gamsaba_s_jnct": -4.2620000000000005, "gamsaba_w1_jnct": -0.3080000000000004, "pepiliyana_e_jnct": -0.14700000000000024, "pepiliyana_jnct": -10.136, "pepiliyana_n2_jnct": -0.7979999999999999, "pepiliyana_s1_jnct": -0.22799999999999998, "pepiliyana_w_jnct": -294.294, "raththanpitiya_jnct": -0.6040000000000001, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 2.7755575615628915e-18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.465149652776168, "mean_inference_ms": 14.328869185844558, "mean_action_processing_ms": 1.2034558856585598, "mean_env_wait_ms": 155.67423241998338, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007035414377848308, "StateBufferConnector_ms": 0.0036706924438476562, "ViewRequirementAgentConnector_ms": 0.08847697575887044}}, "episode_reward_max": -526.9900000000001, "episode_reward_min": -731.5500000000008, "episode_reward_mean": -640.8340000000001, "episode_len_mean": 400.0, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -72.34, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -14.509999999999996, "delkanda_w_jnct": -129.85, "gamsaba_jnct": -236.87, "gamsaba_s_jnct": -12.59, "gamsaba_w1_jnct": -5.480000000000001, "pepiliyana_e_jnct": -1.07, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -2.3900000000000006, "pepiliyana_s1_jnct": -2.28, "pepiliyana_w_jnct": -387.82, "raththanpitiya_jnct": -3.21, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 0.0}, "policy_reward_max": {"delkanda_e2_jnct": -38.52, "delkanda_jnct": -0.29, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -56.81, "gamsaba_jnct": -106.31, "gamsaba_s_jnct": -5.551115123125783e-17, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 0.09000000000000008, "pepiliyana_jnct": -5.77, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 4.996003610813204e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.36000000000000015, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 2.7755575615628914e-17}, "policy_reward_mean": {"delkanda_e2_jnct": -54.14899999999999, "delkanda_jnct": -2.6719999999999997, "delkanda_n2_jnct": -5.520999999999999, "delkanda_w_jnct": -84.54400000000001, "gamsaba_jnct": -183.171, "gamsaba_s_jnct": -4.2620000000000005, "gamsaba_w1_jnct": -0.3080000000000004, "pepiliyana_e_jnct": -0.14700000000000024, "pepiliyana_jnct": -10.136, "pepiliyana_n2_jnct": -0.7979999999999999, "pepiliyana_s1_jnct": -0.22799999999999998, "pepiliyana_w_jnct": -294.294, "raththanpitiya_jnct": -0.6040000000000001, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 2.7755575615628915e-18}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.465149652776168, "mean_inference_ms": 14.328869185844558, "mean_action_processing_ms": 1.2034558856585598, "mean_env_wait_ms": 155.67423241998338, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007035414377848308, "StateBufferConnector_ms": 0.0036706924438476562, "ViewRequirementAgentConnector_ms": 0.08847697575887044}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 60000, "num_agent_steps_trained": 60000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.961734818583538, "num_env_steps_trained_throughput_per_sec": 4.961734818583538, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 60000, "timers": {"training_iteration_time_ms": 806169.57, "sample_time_ms": 711414.56, "learn_time_ms": 94726.453, "learn_throughput": 42.227, "synch_weights_time_ms": 5.79}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 60000, "num_agent_steps_trained": 60000}, "done": false, "episodes_total": 10, "training_iteration": 1, "trial_id": "b024c_00000", "date": "2024-03-18_23-03-13", "timestamp": 1710783193, "time_this_iter_s": 806.1742928028107, "time_total_s": 806.1742928028107, "pid": 306886, "hostname": "LOIT-SE40", "node_ip": "192.168.1.14", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "SumoEnv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping at 0x785770cd7d00>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "resources_per_trial": 2, "horizon": 1500, "soft_horizon": false, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"pepiliyana_jnct": [null, "Box(0.0, 1.0, (21,), float32)", "Discrete(4)", {}], "raththanpitiya_jnct_n4": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_e2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "gamsaba_s_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "pepiliyana_s1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_e_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct_s": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct": [null, "Box(0.0, 1.0, (11,), float32)", "Discrete(2)", {}], "gamsaba_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "gamsaba_w1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 806.1742928028107, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 14.498170731707319, "ram_util_percent": 31.20104529616725}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"raththanpitiya_jnct_n4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.02974036452658311, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0014306570422680427, "policy_loss": 0.0007698155600034322, "vf_loss": 0.0006608418151169341, "vf_explained_var": -0.051715636936326824, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.473067821119912, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.554835374404987, "policy_loss": 0.000743113539647311, "vf_loss": 4.5540922492742535, "vf_explained_var": 0.09194109129408995, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_s_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5928484119901745, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.699653288970391, "policy_loss": 0.0011843018403548437, "vf_loss": 4.698468980689843, "vf_explained_var": 0.0014142395928502082, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_e2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6834087201201329, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.169816382726033, "policy_loss": -0.0012237995843558261, "vf_loss": 9.171040168404579, "vf_explained_var": -1.149158924818039e-05, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3524530978252491, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.48955404162407, "policy_loss": -0.00895528080824685, "vf_loss": 9.496869839231174, "vf_explained_var": 0.007338877208530903, "kl": 0.008197336015763295, "entropy": 1.3515879573921363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_w1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5314898640305425, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.355443202207486, "policy_loss": -0.0007270293373342914, "vf_loss": 3.3561702427764732, "vf_explained_var": 0.04531826606641213, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_s1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9567850169725716, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.33913434950324395, "policy_loss": 0.0008590835624393852, "vf_loss": 0.3382752651736761, "vf_explained_var": 0.3265043173606197, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.979295634540419, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.026363224412004, "policy_loss": -0.015975266408834916, "vf_loss": 3.0387681583563486, "vf_explained_var": 0.17768210638314486, "kl": 0.017851666288098034, "entropy": 1.3278622711698214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48270541657790694, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.846374748150508, "policy_loss": 0.0004257690966672575, "vf_loss": 9.84594899614652, "vf_explained_var": -0.0007421590387821197, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.917404196372081, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.582601181666057, "policy_loss": 0.0002123620344112472, "vf_loss": 9.582388779520988, "vf_explained_var": 0.0030675858880082766, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_e_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6425342056124161, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8845601028452317, "policy_loss": -0.0012660189437156077, "vf_loss": 0.8858261234747867, "vf_explained_var": 0.5118055966372291, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8675245137885212, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5129765943992728, "policy_loss": -0.007582729291364861, "vf_loss": 0.5182801223980884, "vf_explained_var": 0.3002311615894238, "kl": 0.011396016962690943, "entropy": 0.673768360974888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.113534207486858, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.644321843853686, "policy_loss": -0.008749127432141297, "vf_loss": 0.651007367670536, "vf_explained_var": 0.24604400744040808, "kl": 0.0103180119719782, "entropy": 1.3627042715748152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct_s": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1809666581825392, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0791062967289084, "policy_loss": -0.00039416693446886106, "vf_loss": 0.07950046346231829, "vf_explained_var": 0.011230079705516498, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5830229048753002, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11467710584644616, "policy_loss": 0.0012837441431959935, "vf_loss": 0.11339336150267627, "vf_explained_var": 0.1415142805625995, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": -502.64999999999924, "episode_reward_min": -864.4900000000005, "episode_reward_mean": -655.5910000000001, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -95.75, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -32.05, "delkanda_w_jnct": -130.45, "gamsaba_jnct": -328.99, "gamsaba_s_jnct": -65.92, "gamsaba_w1_jnct": -25.040000000000003, "pepiliyana_e_jnct": -1.07, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -4.29, "pepiliyana_s1_jnct": -3.0299999999999994, "pepiliyana_w_jnct": -497.35, "raththanpitiya_jnct": -3.25, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 0.0}, "policy_reward_max": {"delkanda_e2_jnct": -38.52, "delkanda_jnct": -0.29, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -56.81, "gamsaba_jnct": -37.48, "gamsaba_s_jnct": 0.18000000000000077, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 2.11, "pepiliyana_jnct": -0.63, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 6.661338147750939e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.38000000000000067, "raththanpitiya_jnct_n4": 0.01, "raththanpitiya_jnct_s": 0.01999999999999999}, "policy_reward_mean": {"delkanda_e2_jnct": -61.05650000000001, "delkanda_jnct": -2.3754999999999997, "delkanda_n2_jnct": -8.371, "delkanda_w_jnct": -86.9345, "gamsaba_jnct": -167.652, "gamsaba_s_jnct": -7.558000000000002, "gamsaba_w1_jnct": -2.514500000000001, "pepiliyana_e_jnct": 0.029999999999999867, "pepiliyana_jnct": -7.492000000000002, "pepiliyana_n2_jnct": -0.6244999999999999, "pepiliyana_s1_jnct": -0.44149999999999984, "pepiliyana_w_jnct": -309.9035, "raththanpitiya_jnct": -0.699, "raththanpitiya_jnct_n4": 0.0005, "raththanpitiya_jnct_s": 0.0010000000000000009}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998, -805.0600000000002, -597.9699999999992, -705.6800000000027, -502.64999999999924, -674.2000000000019, -864.4900000000005, -638.3900000000002, -567.4799999999999, -649.559999999998, -698.0000000000019], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93, -89.85, -53.62, -52.76, -38.6, -82.67, -58.84, -56.5, -60.87, -95.75, -90.18], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991, -2.5400000000000005, -1.5600000000000003, -3.079999999999998, -2.3200000000000007, -0.33999999999999964, -0.3499999999999993, -0.5299999999999998, -1.4499999999999982, -2.300000000000002, -6.3199999999999985], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0, 0.0, -4.91, -8.31, 0.0, -23.02, -19.44, -32.05, -5.29, -11.89, -7.3], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81, -68.1, -62.38, -84.37, -96.55, -59.28, -76.55, -130.45, -123.32, -124.22, -68.03], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38, -137.95, -210.93, -158.71, -125.31, -207.98, -328.99, -135.94, -40.41, -37.48, -137.63], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17, -4.38, -5.499999999999999, -65.92, -0.24999999999999648, 0.18000000000000077, -24.93, 0.16000000000000003, -1.52, -0.9900000000000002, -5.39], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16, 1.510000000000001, -7.45, -1.734723475976807e-17, -1.69, -3.310000000000001, -8.65, -25.040000000000003, -8.881784197001252e-16, 0.62, -3.2], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018, 5.551115123125783e-17, -0.03999999999999994, -5.551115123125783e-17, 0.0, -2.654126918244515e-16, 0.0, 2.11, 0.0, -2.7755575615628914e-17, 1.1102230246251565e-16], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77, -4.14, -4.040000000000002, -0.63, -10.41, -3.18, -0.72, -11.4, -5.539999999999999, -5.399999999999999, -3.02], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006, 0.0, 0.0, 0.0, 0.0, -0.21999999999999997, 0.0, -4.29, 0.0, 0.0, 0.0], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16, -2.03, 4.440892098500626e-16, -0.14, -0.10999999999999988, -0.019999999999999945, 1.8041124150158794e-16, 1.6653345369377348e-16, -1.219999999999999, -3.0299999999999994, 6.661338147750939e-16], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87, -497.35, -246.64, -331.58, -224.69, -294.04, -342.77, -244.79, -327.36, -369.5, -376.41], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21, -0.22999999999999998, -0.9100000000000003, -0.17999999999999888, -2.74, -0.32000000000000034, -3.25, 0.3300000000000009, -0.5, 0.38000000000000067, -0.5199999999999994], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.4691428556060675, "mean_inference_ms": 14.255416248260062, "mean_action_processing_ms": 1.1989306953630208, "mean_env_wait_ms": 152.5770867999392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00523988405863444, "StateBufferConnector_ms": 0.003627618153889974, "ViewRequirementAgentConnector_ms": 0.08722535769144694}}, "episode_reward_max": -502.64999999999924, "episode_reward_min": -864.4900000000005, "episode_reward_mean": -655.5910000000001, "episode_len_mean": 400.0, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -95.75, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -32.05, "delkanda_w_jnct": -130.45, "gamsaba_jnct": -328.99, "gamsaba_s_jnct": -65.92, "gamsaba_w1_jnct": -25.040000000000003, "pepiliyana_e_jnct": -1.07, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -4.29, "pepiliyana_s1_jnct": -3.0299999999999994, "pepiliyana_w_jnct": -497.35, "raththanpitiya_jnct": -3.25, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": 0.0}, "policy_reward_max": {"delkanda_e2_jnct": -38.52, "delkanda_jnct": -0.29, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -56.81, "gamsaba_jnct": -37.48, "gamsaba_s_jnct": 0.18000000000000077, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 2.11, "pepiliyana_jnct": -0.63, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 6.661338147750939e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.38000000000000067, "raththanpitiya_jnct_n4": 0.01, "raththanpitiya_jnct_s": 0.01999999999999999}, "policy_reward_mean": {"delkanda_e2_jnct": -61.05650000000001, "delkanda_jnct": -2.3754999999999997, "delkanda_n2_jnct": -8.371, "delkanda_w_jnct": -86.9345, "gamsaba_jnct": -167.652, "gamsaba_s_jnct": -7.558000000000002, "gamsaba_w1_jnct": -2.514500000000001, "pepiliyana_e_jnct": 0.029999999999999867, "pepiliyana_jnct": -7.492000000000002, "pepiliyana_n2_jnct": -0.6244999999999999, "pepiliyana_s1_jnct": -0.44149999999999984, "pepiliyana_w_jnct": -309.9035, "raththanpitiya_jnct": -0.699, "raththanpitiya_jnct_n4": 0.0005, "raththanpitiya_jnct_s": 0.0010000000000000009}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998, -805.0600000000002, -597.9699999999992, -705.6800000000027, -502.64999999999924, -674.2000000000019, -864.4900000000005, -638.3900000000002, -567.4799999999999, -649.559999999998, -698.0000000000019], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93, -89.85, -53.62, -52.76, -38.6, -82.67, -58.84, -56.5, -60.87, -95.75, -90.18], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991, -2.5400000000000005, -1.5600000000000003, -3.079999999999998, -2.3200000000000007, -0.33999999999999964, -0.3499999999999993, -0.5299999999999998, -1.4499999999999982, -2.300000000000002, -6.3199999999999985], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0, 0.0, -4.91, -8.31, 0.0, -23.02, -19.44, -32.05, -5.29, -11.89, -7.3], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81, -68.1, -62.38, -84.37, -96.55, -59.28, -76.55, -130.45, -123.32, -124.22, -68.03], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38, -137.95, -210.93, -158.71, -125.31, -207.98, -328.99, -135.94, -40.41, -37.48, -137.63], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17, -4.38, -5.499999999999999, -65.92, -0.24999999999999648, 0.18000000000000077, -24.93, 0.16000000000000003, -1.52, -0.9900000000000002, -5.39], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16, 1.510000000000001, -7.45, -1.734723475976807e-17, -1.69, -3.310000000000001, -8.65, -25.040000000000003, -8.881784197001252e-16, 0.62, -3.2], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018, 5.551115123125783e-17, -0.03999999999999994, -5.551115123125783e-17, 0.0, -2.654126918244515e-16, 0.0, 2.11, 0.0, -2.7755575615628914e-17, 1.1102230246251565e-16], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77, -4.14, -4.040000000000002, -0.63, -10.41, -3.18, -0.72, -11.4, -5.539999999999999, -5.399999999999999, -3.02], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006, 0.0, 0.0, 0.0, 0.0, -0.21999999999999997, 0.0, -4.29, 0.0, 0.0, 0.0], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16, -2.03, 4.440892098500626e-16, -0.14, -0.10999999999999988, -0.019999999999999945, 1.8041124150158794e-16, 1.6653345369377348e-16, -1.219999999999999, -3.0299999999999994, 6.661338147750939e-16], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87, -497.35, -246.64, -331.58, -224.69, -294.04, -342.77, -244.79, -327.36, -369.5, -376.41], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21, -0.22999999999999998, -0.9100000000000003, -0.17999999999999888, -2.74, -0.32000000000000034, -3.25, 0.3300000000000009, -0.5, 0.38000000000000067, -0.5199999999999994], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.4691428556060675, "mean_inference_ms": 14.255416248260062, "mean_action_processing_ms": 1.1989306953630208, "mean_env_wait_ms": 152.5770867999392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00523988405863444, "StateBufferConnector_ms": 0.003627618153889974, "ViewRequirementAgentConnector_ms": 0.08722535769144694}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 5.288381225453324, "num_env_steps_trained_throughput_per_sec": 5.288381225453324, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 781272.329, "sample_time_ms": 685949.724, "learn_time_ms": 95291.944, "learn_throughput": 41.976, "synch_weights_time_ms": 5.989}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 20, "training_iteration": 2, "trial_id": "b024c_00000", "date": "2024-03-18_23-15-50", "timestamp": 1710783950, "time_this_iter_s": 756.3802208900452, "time_total_s": 1562.5545136928558, "pid": 306886, "hostname": "LOIT-SE40", "node_ip": "192.168.1.14", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "SumoEnv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping at 0x785770cd71c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "resources_per_trial": 2, "horizon": 1500, "soft_horizon": false, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"pepiliyana_jnct": [null, "Box(0.0, 1.0, (21,), float32)", "Discrete(4)", {}], "raththanpitiya_jnct_n4": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_e2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "gamsaba_s_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "pepiliyana_s1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_e_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct_s": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct": [null, "Box(0.0, 1.0, (11,), float32)", "Discrete(2)", {}], "gamsaba_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "gamsaba_w1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1562.5545136928558, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 14.395539033457249, "ram_util_percent": 31.600836431226767}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"raththanpitiya_jnct_n4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.01817032432433431, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00025604205299411355, "policy_loss": -0.0006309469258364213, "vf_loss": 0.00037490506718806195, "vf_explained_var": -0.08639764661590259, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3762425849718665, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.9625514164567, "policy_loss": -8.50458423277208e-05, "vf_loss": 5.962636475265026, "vf_explained_var": 0.15341473761945962, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_s_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0346694161805012, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.325027661522229, "policy_loss": -0.0017414684596587903, "vf_loss": 4.326769133160512, "vf_explained_var": 0.36224829126149416, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_e2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.355432218897719, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.494164399802685, "policy_loss": -0.000911516424578925, "vf_loss": 7.49507592022419, "vf_explained_var": -0.00566174096117417, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8516780332351724, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.876367314656575, "policy_loss": -0.00576876645742838, "vf_loss": 9.880864624182383, "vf_explained_var": 0.010662515026827654, "kl": 0.006357246705671526, "entropy": 1.3403577068199715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "gamsaba_w1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.784844471157218, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.534462621062994, "policy_loss": -8.410066608727599e-05, "vf_loss": 4.5345467214783035, "vf_explained_var": -0.0005156199137369791, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_s1_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3972516270664831, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.046343291425243176, "policy_loss": -0.0014250452964915893, "vf_loss": 0.04776833711124103, "vf_explained_var": 0.43199101525048417, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.423026284016669, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3816199027001859, "policy_loss": -0.009957630301748092, "vf_loss": 1.3900200904657443, "vf_explained_var": 0.2592388196537892, "kl": 0.007787208348998111, "entropy": 1.319967710102598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42880767326447916, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.863235200444857, "policy_loss": 0.00018426020736418043, "vf_loss": 9.863050934672355, "vf_explained_var": -0.0016971015681823095, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_w_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.13004174594098, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.52928866247336, "policy_loss": -0.00017828067357186227, "vf_loss": 9.529466941952705, "vf_explained_var": -9.649284183979034e-05, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_e_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1956994733385122, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.730641409754753, "policy_loss": -0.00041296309185175534, "vf_loss": 4.731054365138212, "vf_explained_var": 0.20654036520669858, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8415068085926275, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.541921993655463, "policy_loss": -0.002472280795336701, "vf_loss": 0.5436858805206914, "vf_explained_var": 0.22915286123752593, "kl": 0.0035419683542915422, "entropy": 0.6645699934413035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "delkanda_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9981966830790043, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4145894227277798, "policy_loss": -0.012778562154744577, "vf_loss": 0.4250387554677824, "vf_explained_var": 0.3464978767558932, "kl": 0.011646146817649018, "entropy": 1.3259411270419756, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "raththanpitiya_jnct_s": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1469370186236726, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.06868129179092648, "policy_loss": -0.001088688604553075, "vf_loss": 0.06976998006048234, "vf_explained_var": -0.05559427496045828, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "pepiliyana_n2_jnct": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1045055209320708, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.001718360978217485, "policy_loss": -0.00044102643005317077, "vf_loss": 0.0021593877045233967, "vf_explained_var": 0.0028587045148015023, "kl": 0.0, "entropy": 0.0, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 180000, "num_agent_steps_trained": 180000}, "sampler_results": {"episode_reward_max": -502.64999999999924, "episode_reward_min": -1147.4900000000002, "episode_reward_mean": -733.5460000000006, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -95.75, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -39.66, "delkanda_w_jnct": -130.45, "gamsaba_jnct": -511.06, "gamsaba_s_jnct": -65.92, "gamsaba_w1_jnct": -43.64, "pepiliyana_e_jnct": -26.13, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -4.29, "pepiliyana_s1_jnct": -3.0299999999999994, "pepiliyana_w_jnct": -659.67, "raththanpitiya_jnct": -4.67, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": -4.614364446098307e-16}, "policy_reward_max": {"delkanda_e2_jnct": -26.69, "delkanda_jnct": -0.2600000000000008, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -41.1, "gamsaba_jnct": -37.48, "gamsaba_s_jnct": 0.5000000000000002, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 2.11, "pepiliyana_jnct": -0.479999999999999, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 6.661338147750939e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.38000000000000067, "raththanpitiya_jnct_n4": 0.01, "raththanpitiya_jnct_s": 0.01999999999999999}, "policy_reward_mean": {"delkanda_e2_jnct": -56.727999999999994, "delkanda_jnct": -2.0246666666666666, "delkanda_n2_jnct": -11.300333333333333, "delkanda_w_jnct": -87.56866666666666, "gamsaba_jnct": -192.09599999999998, "gamsaba_s_jnct": -6.922666666666667, "gamsaba_w1_jnct": -5.963333333333334, "pepiliyana_e_jnct": -1.1826666666666668, "pepiliyana_jnct": -5.583666666666667, "pepiliyana_n2_jnct": -0.41633333333333333, "pepiliyana_s1_jnct": -0.2966666666666666, "pepiliyana_w_jnct": -362.61300000000006, "raththanpitiya_jnct": -0.8510000000000001, "raththanpitiya_jnct_n4": 0.0003333333333333333, "raththanpitiya_jnct_s": 0.0006666666666666509}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998, -805.0600000000002, -597.9699999999992, -705.6800000000027, -502.64999999999924, -674.2000000000019, -864.4900000000005, -638.3900000000002, -567.4799999999999, -649.559999999998, -698.0000000000019, -880.0900000000047, -857.6599999999985, -825.3800000000014, -1147.4900000000002, -772.9099999999987, -888.1700000000048, -720.3299999999981, -1040.8899999999994, -1009.240000000001, -752.4000000000033], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93, -89.85, -53.62, -52.76, -38.6, -82.67, -58.84, -56.5, -60.87, -95.75, -90.18, -37.53, -86.84, -28.09, -26.69, -53.18, -64.16, -41.84, -34.24, -53.03, -55.11], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991, -2.5400000000000005, -1.5600000000000003, -3.079999999999998, -2.3200000000000007, -0.33999999999999964, -0.3499999999999993, -0.5299999999999998, -1.4499999999999982, -2.300000000000002, -6.3199999999999985, -0.9799999999999995, -2.5999999999999996, -2.6400000000000006, -0.9299999999999998, -1.5699999999999983, -2.030000000000002, -1.0500000000000007, -0.2600000000000008, -0.5700000000000004, -0.5999999999999986], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0, 0.0, -4.91, -8.31, 0.0, -23.02, -19.44, -32.05, -5.29, -11.89, -7.3, -9.34, -3.59, -9.209999999999999, -20.07, -5.559999999999996, -32.71, -25.229999999999997, -39.66, -7.37, -18.85], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81, -68.1, -62.38, -84.37, -96.55, -59.28, -76.55, -130.45, -123.32, -124.22, -68.03, -118.38, -126.21, -99.15, -102.57, -88.84, -41.1, -79.84, -56.45, -105.39, -70.44], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38, -137.95, -210.93, -158.71, -125.31, -207.98, -328.99, -135.94, -40.41, -37.48, -137.63, -246.89, -181.28, -181.4, -511.06, -117.2, -319.33, -227.95, -216.98, -259.17, -148.58], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17, -4.38, -5.499999999999999, -65.92, -0.24999999999999648, 0.18000000000000077, -24.93, 0.16000000000000003, -1.52, -0.9900000000000002, -5.39, -0.17000000000000084, 0.5000000000000002, -4.46, -3.78, -7.609999999999999, -2.27, -8.700000000000001, -11.24, -1.734723475976807e-17, -18.79], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16, 1.510000000000001, -7.45, -1.734723475976807e-17, -1.69, -3.310000000000001, -8.65, -25.040000000000003, -8.881784197001252e-16, 0.62, -3.2, -0.63, 1.5400000000000005, -12.78, -28.12, 0.0, -43.64, -18.44, -18.65, -5.199999999999999, -2.6899999999999995], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018, 5.551115123125783e-17, -0.03999999999999994, -5.551115123125783e-17, 0.0, -2.654126918244515e-16, 0.0, 2.11, 0.0, -2.7755575615628914e-17, 1.1102230246251565e-16, -26.13, 0.53, -1.93, 0.13, -4.98, 2.220446049250313e-16, 2.220446049250313e-16, -1.31, -2.949029909160572e-17, -2.39], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77, -4.14, -4.040000000000002, -0.63, -10.41, -3.18, -0.72, -11.4, -5.539999999999999, -5.399999999999999, -3.02, -0.7799999999999983, -0.479999999999999, -1.52, -1.24, -1.92, -3.42, -2.7199999999999993, -2.0000000000000018, -2.33, -1.26], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006, 0.0, 0.0, 0.0, 0.0, -0.21999999999999997, 0.0, -4.29, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16, -2.03, 4.440892098500626e-16, -0.14, -0.10999999999999988, -0.019999999999999945, 1.8041124150158794e-16, 1.6653345369377348e-16, -1.219999999999999, -3.0299999999999994, 6.661338147750939e-16, 5.551115123125783e-17, -0.01999999999999989, -1.734723475976807e-17, 0.0, 1.0408340855860843e-17, -0.050000000000000225, 1.3877787807814457e-17, 1.0408340855860843e-17, -2.220446049250313e-16, -1.734723475976807e-17], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87, -497.35, -246.64, -331.58, -224.69, -294.04, -342.77, -244.79, -327.36, -369.5, -376.41, -436.92, -457.86, -482.37, -453.43, -487.38, -379.35, -313.91, -659.67, -575.93, -433.5], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21, -0.22999999999999998, -0.9100000000000003, -0.17999999999999888, -2.74, -0.32000000000000034, -3.25, 0.3300000000000009, -0.5, 0.38000000000000067, -0.5199999999999994, -2.34, -1.3500000000000005, -1.8299999999999983, 0.2699999999999998, -4.67, -0.11000000000000033, -0.6500000000000007, -0.4299999999999999, -0.25, -0.1900000000000011], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.7755575615628914e-17, 0.0, -4.614364446098307e-16, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.479885998092668, "mean_inference_ms": 14.22135158038893, "mean_action_processing_ms": 1.1971762303993474, "mean_env_wait_ms": 151.2628235415182, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004645718468560113, "StateBufferConnector_ms": 0.0036305321587456595, "ViewRequirementAgentConnector_ms": 0.0873858133951823}}, "episode_reward_max": -502.64999999999924, "episode_reward_min": -1147.4900000000002, "episode_reward_mean": -733.5460000000006, "episode_len_mean": 400.0, "episodes_this_iter": 10, "policy_reward_min": {"delkanda_e2_jnct": -95.75, "delkanda_jnct": -9.230000000000002, "delkanda_n2_jnct": -39.66, "delkanda_w_jnct": -130.45, "gamsaba_jnct": -511.06, "gamsaba_s_jnct": -65.92, "gamsaba_w1_jnct": -43.64, "pepiliyana_e_jnct": -26.13, "pepiliyana_jnct": -13.629999999999997, "pepiliyana_n2_jnct": -4.29, "pepiliyana_s1_jnct": -3.0299999999999994, "pepiliyana_w_jnct": -659.67, "raththanpitiya_jnct": -4.67, "raththanpitiya_jnct_n4": 0.0, "raththanpitiya_jnct_s": -4.614364446098307e-16}, "policy_reward_max": {"delkanda_e2_jnct": -26.69, "delkanda_jnct": -0.2600000000000008, "delkanda_n2_jnct": 0.0, "delkanda_w_jnct": -41.1, "gamsaba_jnct": -37.48, "gamsaba_s_jnct": 0.5000000000000002, "gamsaba_w1_jnct": 2.86, "pepiliyana_e_jnct": 2.11, "pepiliyana_jnct": -0.479999999999999, "pepiliyana_n2_jnct": 0.0, "pepiliyana_s1_jnct": 6.661338147750939e-16, "pepiliyana_w_jnct": -157.38, "raththanpitiya_jnct": 0.38000000000000067, "raththanpitiya_jnct_n4": 0.01, "raththanpitiya_jnct_s": 0.01999999999999999}, "policy_reward_mean": {"delkanda_e2_jnct": -56.727999999999994, "delkanda_jnct": -2.0246666666666666, "delkanda_n2_jnct": -11.300333333333333, "delkanda_w_jnct": -87.56866666666666, "gamsaba_jnct": -192.09599999999998, "gamsaba_s_jnct": -6.922666666666667, "gamsaba_w1_jnct": -5.963333333333334, "pepiliyana_e_jnct": -1.1826666666666668, "pepiliyana_jnct": -5.583666666666667, "pepiliyana_n2_jnct": -0.41633333333333333, "pepiliyana_s1_jnct": -0.2966666666666666, "pepiliyana_w_jnct": -362.61300000000006, "raththanpitiya_jnct": -0.8510000000000001, "raththanpitiya_jnct_n4": 0.0003333333333333333, "raththanpitiya_jnct_s": 0.0006666666666666509}, "hist_stats": {"episode_reward": [-702.9000000000002, -639.0899999999999, -526.9900000000001, -667.4600000000046, -683.0400000000003, -615.6399999999973, -532.0199999999984, -731.5500000000008, -624.2099999999986, -685.4399999999998, -805.0600000000002, -597.9699999999992, -705.6800000000027, -502.64999999999924, -674.2000000000019, -864.4900000000005, -638.3900000000002, -567.4799999999999, -649.559999999998, -698.0000000000019, -880.0900000000047, -857.6599999999985, -825.3800000000014, -1147.4900000000002, -772.9099999999987, -888.1700000000048, -720.3299999999981, -1040.8899999999994, -1009.240000000001, -752.4000000000033], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_delkanda_e2_jnct_reward": [-54.01, -57.68, -45.42, -42.47, -52.24, -38.52, -58.6, -72.34, -64.28, -55.93, -89.85, -53.62, -52.76, -38.6, -82.67, -58.84, -56.5, -60.87, -95.75, -90.18, -37.53, -86.84, -28.09, -26.69, -53.18, -64.16, -41.84, -34.24, -53.03, -55.11], "policy_delkanda_jnct_reward": [-1.040000000000001, -3.95, -1.7299999999999995, -3.460000000000001, -2.200000000000001, -3.9399999999999964, -0.36000000000000004, -9.230000000000002, -0.29, -0.5199999999999991, -2.5400000000000005, -1.5600000000000003, -3.079999999999998, -2.3200000000000007, -0.33999999999999964, -0.3499999999999993, -0.5299999999999998, -1.4499999999999982, -2.300000000000002, -6.3199999999999985, -0.9799999999999995, -2.5999999999999996, -2.6400000000000006, -0.9299999999999998, -1.5699999999999983, -2.030000000000002, -1.0500000000000007, -0.2600000000000008, -0.5700000000000004, -0.5999999999999986], "policy_delkanda_n2_jnct_reward": [-11.809999999999999, -10.02, -5.550000000000002, -4.46, -14.509999999999996, -4.91, 0.0, 0.0, -3.95, 0.0, 0.0, -4.91, -8.31, 0.0, -23.02, -19.44, -32.05, -5.29, -11.89, -7.3, -9.34, -3.59, -9.209999999999999, -20.07, -5.559999999999996, -32.71, -25.229999999999997, -39.66, -7.37, -18.85], "policy_delkanda_w_jnct_reward": [-129.85, -57.9, -98.28, -83.84, -99.99, -67.72, -75.42, -100.64, -74.99, -56.81, -68.1, -62.38, -84.37, -96.55, -59.28, -76.55, -130.45, -123.32, -124.22, -68.03, -118.38, -126.21, -99.15, -102.57, -88.84, -41.1, -79.84, -56.45, -105.39, -70.44], "policy_gamsaba_jnct_reward": [-236.87, -197.87, -195.87, -135.44, -155.38, -167.1, -106.31, -230.24, -230.25, -176.38, -137.95, -210.93, -158.71, -125.31, -207.98, -328.99, -135.94, -40.41, -37.48, -137.63, -246.89, -181.28, -181.4, -511.06, -117.2, -319.33, -227.95, -216.98, -259.17, -148.58], "policy_gamsaba_s_jnct_reward": [-7.4, -5.86, -4.996003610813204e-16, -0.8500000000000001, -5.92, -0.11, -4.59, -5.299999999999998, -12.59, -5.551115123125783e-17, -4.38, -5.499999999999999, -65.92, -0.24999999999999648, 0.18000000000000077, -24.93, 0.16000000000000003, -1.52, -0.9900000000000002, -5.39, -0.17000000000000084, 0.5000000000000002, -4.46, -3.78, -7.609999999999999, -2.27, -8.700000000000001, -11.24, -1.734723475976807e-17, -18.79], "policy_gamsaba_w1_jnct_reward": [-1.5600000000000003, 1.3877787807814457e-17, -5.480000000000001, -0.65, 2.86, 0.9999999999999982, -1.457167719820518e-16, 0.9099999999999998, 4.440892098500626e-16, -0.16, 1.510000000000001, -7.45, -1.734723475976807e-17, -1.69, -3.310000000000001, -8.65, -25.040000000000003, -8.881784197001252e-16, 0.62, -3.2, -0.63, 1.5400000000000005, -12.78, -28.12, 0.0, -43.64, -18.44, -18.65, -5.199999999999999, -2.6899999999999995], "policy_pepiliyana_e_jnct_reward": [0.0, 8.326672684688674e-17, 5.551115123125783e-17, 0.09000000000000008, 0.0, -1.07, -0.08000000000000002, -8.881784197001252e-16, -0.010000000000000009, -0.4000000000000018, 5.551115123125783e-17, -0.03999999999999994, -5.551115123125783e-17, 0.0, -2.654126918244515e-16, 0.0, 2.11, 0.0, -2.7755575615628914e-17, 1.1102230246251565e-16, -26.13, 0.53, -1.93, 0.13, -4.98, 2.220446049250313e-16, 2.220446049250313e-16, -1.31, -2.949029909160572e-17, -2.39], "policy_pepiliyana_jnct_reward": [-6.5, -8.16, -13.46, -8.34, -7.43, -13.629999999999997, -11.8, -12.99, -13.28, -5.77, -4.14, -4.040000000000002, -0.63, -10.41, -3.18, -0.72, -11.4, -5.539999999999999, -5.399999999999999, -3.02, -0.7799999999999983, -0.479999999999999, -1.52, -1.24, -1.92, -3.42, -2.7199999999999993, -2.0000000000000018, -2.33, -1.26], "policy_pepiliyana_n2_jnct_reward": [0.0, -0.0699999999999999, -1.0099999999999996, -0.2599999999999999, 0.0, -1.01, -1.9700000000000002, -0.5499999999999999, -0.7200000000000001, -2.3900000000000006, 0.0, 0.0, 0.0, 0.0, -0.21999999999999997, 0.0, -4.29, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_pepiliyana_s1_jnct_reward": [0.0, -5.551115123125783e-17, -2.28, 0.0, 0.0, 0.0, 4.996003610813204e-16, 0.0, -1.4224732503009818e-16, -2.7755575615628914e-16, -2.03, 4.440892098500626e-16, -0.14, -0.10999999999999988, -0.019999999999999945, 1.8041124150158794e-16, 1.6653345369377348e-16, -1.219999999999999, -3.0299999999999994, 6.661338147750939e-16, 5.551115123125783e-17, -0.01999999999999989, -1.734723475976807e-17, 0.0, 1.0408340855860843e-17, -0.050000000000000225, 1.3877787807814457e-17, 1.0408340855860843e-17, -2.220446049250313e-16, -1.734723475976807e-17], "policy_pepiliyana_w_jnct_reward": [-253.8, -297.06, -157.38, -387.82, -348.59, -318.49, -272.43, -299.69, -223.81, -383.87, -497.35, -246.64, -331.58, -224.69, -294.04, -342.77, -244.79, -327.36, -369.5, -376.41, -436.92, -457.86, -482.37, -453.43, -487.38, -379.35, -313.91, -659.67, -575.93, -433.5], "policy_raththanpitiya_jnct_reward": [-0.05999999999999997, -0.52, -0.5299999999999994, 0.03999999999999909, 0.36000000000000015, -0.13999999999999968, -0.4599999999999998, -1.4800000000000009, -0.03999999999999998, -3.21, -0.22999999999999998, -0.9100000000000003, -0.17999999999999888, -2.74, -0.32000000000000034, -3.25, 0.3300000000000009, -0.5, 0.38000000000000067, -0.5199999999999994, -2.34, -1.3500000000000005, -1.8299999999999983, 0.2699999999999998, -4.67, -0.11000000000000033, -0.6500000000000007, -0.4299999999999999, -0.25, -0.1900000000000011], "policy_raththanpitiya_jnct_n4_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_raththanpitiya_jnct_s_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7755575615628914e-17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01999999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.7755575615628914e-17, 0.0, -4.614364446098307e-16, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.479885998092668, "mean_inference_ms": 14.22135158038893, "mean_action_processing_ms": 1.1971762303993474, "mean_env_wait_ms": 151.2628235415182, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004645718468560113, "StateBufferConnector_ms": 0.0036305321587456595, "ViewRequirementAgentConnector_ms": 0.0873858133951823}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 180000, "num_agent_steps_trained": 180000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 5.147653850624674, "num_env_steps_trained_throughput_per_sec": 5.147653850624674, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 180000, "timers": {"training_iteration_time_ms": 779865.88, "sample_time_ms": 682532.85, "learn_time_ms": 97302.946, "learn_throughput": 41.109, "synch_weights_time_ms": 6.051}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 180000, "num_agent_steps_trained": 180000}, "done": true, "episodes_total": 30, "training_iteration": 3, "trial_id": "b024c_00000", "date": "2024-03-18_23-28-47", "timestamp": 1710784727, "time_this_iter_s": 777.0587046146393, "time_total_s": 2339.613218307495, "pid": 306886, "hostname": "LOIT-SE40", "node_ip": "192.168.1.14", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "SumoEnv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "validate_workers_after_construction": true, "compress_observations": false, "sampler_perf_stats_ema_coef": null, "sample_async": -1, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function policy_mapping at 0x785770dbe680>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_enable_new_api_stack": false, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "resources_per_trial": 2, "horizon": 1500, "soft_horizon": false, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"pepiliyana_jnct": [null, "Box(0.0, 1.0, (21,), float32)", "Discrete(4)", {}], "raththanpitiya_jnct_n4": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_e2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "gamsaba_s_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "pepiliyana_s1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_e_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct_s": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "delkanda_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_w_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "raththanpitiya_jnct": [null, "Box(0.0, 1.0, (11,), float32)", "Discrete(2)", {}], "gamsaba_jnct": [null, "Box(0.0, 1.0, (17,), float32)", "Discrete(4)", {}], "gamsaba_w1_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}], "pepiliyana_n2_jnct": [null, "Box(0.0, 1.0, (4,), float32)", "Discrete(1)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2339.613218307495, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 14.420886075949367, "ram_util_percent": 32.037974683544306}}
